


import cv2
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader

# Define the model architecture
class HumanPoseEstimationModel(nn.Module):
    def __init__(self):
        super(HumanPoseEstimationModel, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3)
        self.conv2 = nn.Conv2d(64, 128, kernel_size=3)
        self.conv3 = nn.Conv2d(128, 256, kernel_size=3)
        self.fc1 = nn.Linear(256*32*32, 128)
        self.fc2 = nn.Linear(128, 16)

    def forward(self, x):
        x = nn.functional.relu(nn.functional.max_pool2d(self.conv1(x), 2))
        x = nn.functional.relu(nn.functional.max_pool2d(self.conv2(x), 2))
        x = nn.functional.relu(nn.functional.max_pool2d(self.conv3(x), 2))
        x = x.view(-1, 256*32*32)
        x = nn.functional.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# Load the dataset
class HumanPoseEstimationDataset(Dataset):
    def __init__(self, image_paths, pose_paths):
        self.image_paths = image_paths
        self.pose_paths = pose_paths

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, index):
        image = cv2.imread(self.image_paths[index])
        pose = np.load(self.pose_paths[index])
        return image, pose

# Train the model
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
model = HumanPoseEstimationModel()
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

train_dataset = HumanPoseEstimationDataset(train_image_paths, train_pose_paths)
train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)

for epoch in range(10):
    for images, poses in train_dataloader:
        images = images.to(device)
        poses = poses.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, poses)
        loss.backward()
        optimizer.step()
    print(f"Epoch {epoch+1}, Loss: {loss.item()}")

# Evaluate the model
test_dataset = HumanPoseEstimationDataset(test_image_paths, test_pose_paths)
test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)

model.eval()
with torch.no_grad():
    total_loss = 0
    for images, poses in test_dataloader:
        images = images.to(device)
        poses = poses.to(device)
        outputs = model(images)
        loss = criterion(outputs, poses)
        total_loss += loss.item()
    average_loss = total_loss / len(test_dataloader)
    print(f"Test Loss: {average_loss}")


